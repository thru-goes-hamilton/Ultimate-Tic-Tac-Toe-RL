{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    won_check = np.array([[0,1,2],[3,4,5],[6,7,8],[0,3,6],[1,4,7],[2,5,8],[0,4,8],[2,4,6]])\n",
    "\n",
    "    def __init__(self, board_state,previous_move=-1):\n",
    "\n",
    "        self.board_state = board_state # state of the board\n",
    "        self.won_flag = [] # a list of 9 elements corresponding to who has won which board\n",
    "        self.moves_left = [] # a list of moves completed in each subboard\n",
    "        self.no_of_moves_left = [] # no. of moves left in each subboard\n",
    "        self.previous_move = previous_move\n",
    "        self.first = np.all(self.board_state==0) # whether game has started or not\n",
    "        \n",
    "        for i in range(self.board_state.shape[0]):#Traversing every sub board\n",
    "            self.won_flag.append(self.check_result_board(self.board_state[i]))\n",
    "            self.moves_left.append(self.board_state[i] == 0)\n",
    "            self.no_of_moves_left.append(np.count_nonzero(self.board_state[i] == 0))\n",
    "        \n",
    "        \n",
    "        self.finish = self.check_result_board(self.won_flag) # whether game is finished or not\n",
    "\n",
    "    def check_result_board(self, arr):\n",
    "        arr = np.array(arr)\n",
    "        for triplet in State.won_check:\n",
    "            values = arr[triplet]\n",
    "            if np.all(values == values[0]):\n",
    "                return values[0]\n",
    "        if np.count_nonzero(arr==0)==0:\n",
    "            return -2 #-2 is to signify a draw at any subboard or the final board\n",
    "        return 0\n",
    "    \n",
    "    def update_state(self,move,player): #player should be either -1 or +1\n",
    "        updated_state = copy.deepcopy(self)\n",
    "        updated_state.previous_move = move\n",
    "        # print(f\"chosen move: {move}\")\n",
    "        updated_state.board_state[move//9,move%9]=player\n",
    "        for i in range(updated_state.board_state.shape[0]):#Traversing every sub board\n",
    "            updated_state.won_flag[i] = updated_state.check_result_board(updated_state.board_state[i])\n",
    "\n",
    "            updated_state.moves_left[i] = updated_state.board_state[i] == 0\n",
    "            updated_state.no_of_moves_left[i] = np.count_nonzero(updated_state.board_state[i] == 0)\n",
    "        updated_state.first = np.all(updated_state.board_state==0)\n",
    "        updated_state.finish = updated_state.check_result_board(updated_state.won_flag)\n",
    "        \n",
    "        return updated_state\n",
    "\n",
    "\n",
    "    def format_board(self):\n",
    "        display_board = np.zeros((9,9))\n",
    "        for x in [3,6,9]:\n",
    "            for i in range(x-3,x):\n",
    "                for y in [3,6,9]:\n",
    "                    for j in range(y-3,y):\n",
    "                        display_board[(i//3)*3+(j//3),3*(i%3)+(j%3)]=self.board_state[i,j]\n",
    "        return display_board\n",
    "    \n",
    "    def print_board(self):\n",
    "        display_board = self.format_board()\n",
    "                        # print(f\"old index{i},{j}\\nnew index {(i//3)*3+(j//3)},{3*(i%3)+(j%3)}\\nupdated value{display_board[(i//3)*3+(j//3),3*(i%3)+(j%3)]}\")\n",
    "        \n",
    "        for i in range(9):\n",
    "            # Print horizontal divider after every 3 rows\n",
    "            if i % 3 == 0 and i != 0:\n",
    "                print(\"-\" * 31)  # Adjusted width for better alignment\n",
    "            \n",
    "            row = \"\"\n",
    "            for j in range(9):\n",
    "                # Add vertical divider after every 3 columns\n",
    "                if j % 3 == 0 and j != 0:\n",
    "                    row += \"| \"\n",
    "                # Add extra spacing for '1' to maintain alignment\n",
    "                if display_board[i, j] != -1:\n",
    "                    row += f\" {int(display_board[i,j])} \"  # Extra space before '1'\n",
    "                else:\n",
    "                    row += f\"{int(display_board[i, j])} \"  # Ensure consistent width for other values\n",
    "            print(row)\n",
    "\n",
    "    def legal_moves(self):\n",
    "        legal_moves=[]\n",
    "\n",
    "        if self.first == True:\n",
    "            for i in range(len(self.moves_left)):\n",
    "                for j in range(len(self.moves_left[0])):\n",
    "                    legal_moves.append(i*9+j)\n",
    "        elif self.finish == 0:\n",
    "            i = self.previous_move%9\n",
    "            if self.won_flag[i] == 0:\n",
    "                for j in range(len(self.moves_left[0])):\n",
    "                    if self.moves_left[i][j]:\n",
    "                        legal_moves.append(i*9+j)\n",
    "            else:\n",
    "                for i in range(len(self.moves_left)):\n",
    "                    if self.won_flag[i] == 0:\n",
    "                        for j in range(len(self.moves_left[0])):\n",
    "                            if self.moves_left[i][j]:\n",
    "                                legal_moves.append(i*9+j)\n",
    "\n",
    "        \n",
    "        return legal_moves\n",
    "\n",
    "    def inspect_board(self):\n",
    "        print(self.board_state)\n",
    "\n",
    "    def print_won_flag(self):\n",
    "        for i in range(3):  # 3 rows\n",
    "            row = \"\"\n",
    "            for j in range(3):  # 3 columns\n",
    "                value = self.won_flag[i * 3 + j]\n",
    "                # Add extra space before 0 and 1 for formatting\n",
    "                if value in [0, 1]:\n",
    "                    row += f\"  {int(value)}\"\n",
    "                else:\n",
    "                    row += f\" {int(value)}\"\n",
    "                # Add column separator if not the last column\n",
    "                if j < 2:\n",
    "                    row += \" |\"\n",
    "            print(row)\n",
    "            # Add row separator if not the last row\n",
    "            if i < 2:\n",
    "                print(\"----+----+----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTSNode:\n",
    "    def __init__(self,state = None,total_score = 0,visit_count = 0):\n",
    "        self.state = state\n",
    "        self.total_score = total_score\n",
    "        self.visit_count = visit_count\n",
    "        self.children = []\n",
    "        self.action = []\n",
    "        self.parent = None\n",
    "\n",
    "    def add_child(self,child_node,action):\n",
    "        child_node.parent = self\n",
    "        self.children.append(child_node)\n",
    "        self.action.append(action)\n",
    "        return self\n",
    "    \n",
    "    def prior_probability(self):\n",
    "        return 1/(len(self.state.legal_moves()))\n",
    "\n",
    "    def calculate_UCT_score(self, c = 1.25):\n",
    "        if self.visit_count != 0:\n",
    "            UCT_score = (self.total_score/self.visit_count) + c* (self.prior_probability())* (math.sqrt(self.parent.visit_count))/(1+self.visit_count)\n",
    "        else:\n",
    "            UCT_score = 10000\n",
    "        return UCT_score\n",
    "    \n",
    "    def normalize_visit_count(self):\n",
    "        visit_count_of_children = [child.visit_count for child in self.children]\n",
    "        action_count_of_children = [action for action in self.action]\n",
    "        probability_distribution = []\n",
    "        for i in range(81):\n",
    "            if i in action_count_of_children:\n",
    "                index = self.action.index(i)\n",
    "                probability_distribution.append(visit_count_of_children[index])\n",
    "            else:\n",
    "                probability_distribution.append(0)\n",
    "\n",
    "        max_count = max(probability_distribution)\n",
    "        exp_values = [math.exp(count - max_count) for count in probability_distribution]\n",
    "        total = sum(exp_values)\n",
    "        normalized_visit_count = [value / total for value in exp_values]\n",
    "        return normalized_visit_count\n",
    "\n",
    "    \n",
    "    def max_visit_count(self):\n",
    "        visit_count_of_children = [child.visit_count for child in self.children]\n",
    "        action_index = visit_count_of_children.index(max(visit_count_of_children))\n",
    "        return self.action[action_index]\n",
    "\n",
    "    def is_root(self):\n",
    "        return self.parent is None\n",
    "    \n",
    "    def is_leaf(self):\n",
    "        return len(self.children) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection(current_node,current_player):\n",
    "    # print(\"Selecting...\")\n",
    "    depth = 0\n",
    "    while not current_node.is_leaf():\n",
    "        UCT_values = [] #UCT score values calculated for each possible action in legal moves\n",
    "        for child in current_node.children:\n",
    "            if child.state.finish==1 or child.state.finish==-1:\n",
    "                UCT_values.append(child.state.finish)\n",
    "            elif child.state.finish==-2:\n",
    "                UCT_values.append(0)\n",
    "            else:\n",
    "                UCT_values.append(child.calculate_UCT_score())\n",
    "        \n",
    "        if current_player>0:\n",
    "            max_UCT_value = max(UCT_values)\n",
    "            max_UCT_index = UCT_values.index(max_UCT_value)\n",
    "            current_node = current_node.children[max_UCT_index]\n",
    "            # print(f\"Max UCT value: {max_UCT_value}\\nUCT index: {max_UCT_index+1}\\nPlayer:{current_player}\")\n",
    "        elif current_player<0:\n",
    "            min_UCT_value = min(UCT_values)\n",
    "            min_UCT_index = UCT_values.index(min_UCT_value)\n",
    "            current_node = current_node.children[min_UCT_index]\n",
    "            # print(f\"Min UCT value: {min_UCT_value}\\nUCT index: {min_UCT_index+1}\\nPlayer:{current_player}\")\n",
    "\n",
    "        \n",
    "        current_player = current_player * (-1)\n",
    "        depth+=1\n",
    "        # print(f\"Selecting at depth {depth}...\")\n",
    "        \n",
    "    # print(\"Selection complete\")\n",
    "    return current_node,current_player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expansion(current_node,current_player):\n",
    "    # print(\"Expanding...\")\n",
    "    if current_node.state.finish != 0:\n",
    "        # print(\"found terminal state while expanding\")\n",
    "        return current_node\n",
    "    for action in current_node.state.legal_moves():\n",
    "        current_node = current_node.add_child(child_node=MCTSNode(state =current_node.state.update_state(move=action,player=current_player)),action = action)\n",
    "    \n",
    "    current_node=random.choice(current_node.children)\n",
    "    # print(f\"Chosen:\")\n",
    "    # current_node.state.print_board()\n",
    "    # print(\"Expanded\")\n",
    "    return current_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_from_state(state):\n",
    "    # print(\"Simulating...\")\n",
    "    i=1\n",
    "    simulation_count = 0\n",
    "    while state.finish == 0:\n",
    "        state = state.update_state(move=random.choice(state.legal_moves()),player=i)\n",
    "        i=i*(-1)\n",
    "        simulation_count=simulation_count+1\n",
    "    \n",
    "    # print(f\"No. of moves played: {simulation_count}\")\n",
    "    # print(f\"Result: {state.finish}\")\n",
    "    # print(\"Final board\")\n",
    "    # state.print_board()\n",
    "    # print(\"Mini board\")\n",
    "    # state.print_won_flag()\n",
    "\n",
    "    # print(\"Simulated\")\n",
    "\n",
    "    return state.finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(current_node, value):\n",
    "    # print(\"Backpropagating...\")\n",
    "    while not current_node.is_root():\n",
    "        current_node.visit_count +=1\n",
    "        current_node.total_score += value\n",
    "        current_node = current_node.parent\n",
    "        \n",
    "    \n",
    "    current_node.visit_count +=1\n",
    "    current_node.total_score += value\n",
    "    # print(f\"Visit count of root: {current_node.visit_count}\\nTotal score of root: {current_node.total_score}\")\n",
    "    # print(\"Backpropagated\")\n",
    "    \n",
    "    return current_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_MCTS(state,simulation_limiter,player,policy_network_X,policy_network_y):\n",
    "    # print(\"MCTS...\")\n",
    "    current_node = MCTSNode(state=state)\n",
    "    # print(f\"Created root node for MCTS\")\n",
    "    # for i in tqdm(range(simulation_limiter), desc=\"Simulating MCTS\"):\n",
    "    for i in range(simulation_limiter):\n",
    "        # print(f\"MCTS attempt {i+1}\")\n",
    "        current_node,current_player = selection(current_node=current_node,current_player=player)\n",
    "        current_node = expansion(current_node=current_node,current_player=current_player)\n",
    "        simulated_result = simulate_from_state(current_node.state)\n",
    "\n",
    "        if simulated_result == -2:\n",
    "            simulated_result = 0\n",
    "\n",
    "        current_node = backpropagation(current_node=current_node,value=simulated_result)\n",
    "    # print(f\"MCTS attempt {i+1} completed\")\n",
    "    policy_network_X.append(current_node.state.board_state)\n",
    "    policy_network_y.append(current_node.normalize_visit_count())\n",
    "    # print(f\"Added board:\\n{current_node.state.board_state}\\nAdded labels: {current_node.normalize_visit_count()}\")\n",
    "    return current_node.max_visit_count()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selfplay(iteration):\n",
    "    policy_network_X = []\n",
    "    policy_network_y = []\n",
    "    value_network_X = []\n",
    "    value_network_y = []\n",
    "    state = State(board_state=np.zeros((9,9)))\n",
    "    player=1\n",
    "    move_count = 0\n",
    "    # with tqdm(total =  0, desc = \"Selfplay Moves\", unit = \"move\") as pbar:\n",
    "    while state.finish == 0:\n",
    "        # pbar.set_description(f\"Move count: {move_count}\")\n",
    "        # start_time = time.time()\n",
    "\n",
    "        # print(f\"Move count: {move_count}\")\n",
    "        move_to_play = create_MCTS(state=state,simulation_limiter=800,player=player,policy_network_X=policy_network_X,policy_network_y=policy_network_y)\n",
    "        state = state.update_state(move=move_to_play,player=player)\n",
    "        # print(f\"Move played by player {player}: {move_to_play}\")\n",
    "        value_network_X.append(state.board_state)\n",
    "        # print(f\"Current Board: {state.print_board()}\")\n",
    "\n",
    "        # elapsed_time = time.time()-start_time\n",
    "        # pbar.update(1)\n",
    "        # pbar.set_postfix(time = f\"{elapsed_time:.2f}s\")\n",
    "\n",
    "        player=player*(-1)\n",
    "        move_count=move_count+1\n",
    "    \n",
    "    if state.finish == -2:\n",
    "        result = 0\n",
    "    else:\n",
    "        result = state.finish\n",
    "    # print(\"---Game completed---\")\n",
    "    # print(f\"Result: {result}\\nFinal Board:\")\n",
    "    # state.print_board()\n",
    "\n",
    "    for i in range(move_count):\n",
    "        value_network_y.append(result)\n",
    "\n",
    "    data = {\n",
    "        'value_network_X': value_network_X,\n",
    "        'value_network_y': value_network_y,\n",
    "        'policy_network_X': policy_network_X,\n",
    "        'policy_network_y': policy_network_y\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    df.to_csv(f'mcts_data{iteration}.csv', index=False)\n",
    "\n",
    "    # from google.colab import files\n",
    "    # files.download(f'mcts_data{iteration}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    selfplay(i+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultimate_tictactoe_rl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
